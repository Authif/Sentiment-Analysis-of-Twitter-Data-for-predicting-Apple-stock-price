{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fear and greed sentiment data for AAPL\n",
    "df = pd.read_csv('AAPL.csv', index_col=\"Date\", infer_datetime_format=True, parse_dates=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"Adj Close\", \"ts_polarity\", \"twitter_volume\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Pct_change\"] = df[\"Adj Close\"].pct_change()\n",
    "df.dropna(inplace = True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function accepts the column number for the features (X) and the target (y)\n",
    "# It chunks the data up with a rolling window of Xt-n to predict Xt\n",
    "# It returns a numpy array of X any y\n",
    "def window_data(df, window, feature_col_number1, feature_col_number2, feature_col_number3, target_col_number):\n",
    "    X_close = []\n",
    "    X_polarity = []\n",
    "    X_volume = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window):\n",
    "        close = df.iloc[i:(i + window), feature_col_number1]\n",
    "        ts_polarity = df.iloc[i:(i + window), feature_col_number2]\n",
    "        tw_vol = df.iloc[i:(i + window), feature_col_number3]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X_close.append(close)\n",
    "        X_polarity.append(ts_polarity)\n",
    "        X_volume.append(tw_vol)\n",
    "        y.append(target)\n",
    "    return np.hstack((X_close,X_polarity,X_volume)), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Closing Prices using a 10 day window of previous closing prices\n",
    "# Then, experiment with window sizes anywhere from 1 to 10 and see how the model performance changes\n",
    "window_size = 3\n",
    "\n",
    "# Column index 1 is the `Close` column\n",
    "feature_col_number1 = 0\n",
    "feature_col_number2 = 1\n",
    "feature_col_number3 = 2\n",
    "target_col_number = 0\n",
    "X, y = window_data(df, window_size, feature_col_number1, feature_col_number2, feature_col_number3, target_col_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 70% of the data for training and the remaineder for testing\n",
    "X_split = int(0.7 * len(X))\n",
    "y_split = int(0.7 * len(y))\n",
    "\n",
    "X_train = X[: X_split]\n",
    "X_test = X[X_split:]\n",
    "y_train = y[: y_split]\n",
    "y_test = y[y_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Use the MinMaxScaler to scale data between 0 and 1.\n",
    "x_train_scaler = MinMaxScaler()\n",
    "x_test_scaler = MinMaxScaler()\n",
    "y_train_scaler = MinMaxScaler()\n",
    "y_test_scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler for the Training Data\n",
    "x_train_scaler.fit(X_train)\n",
    "y_train_scaler.fit(y_train)\n",
    "\n",
    "# Scale the training data\n",
    "X_train = x_train_scaler.transform(X_train)\n",
    "y_train = y_train_scaler.transform(y_train)\n",
    "\n",
    "# Fit the scaler for the Testing Data\n",
    "x_test_scaler.fit(X_test)\n",
    "y_test_scaler.fit(y_test)\n",
    "\n",
    "# Scale the y_test data\n",
    "X_test = x_test_scaler.transform(X_test)\n",
    "y_test = y_test_scaler.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the XG Boost regressor instance\n",
    "model = RandomForestRegressor(n_estimators=1, max_depth=2, bootstrap=False, min_samples_leaf=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance\n",
    "\n",
    "In this section, you will evaluate the model using the test data. \n",
    "\n",
    "You will need to:\n",
    "1. Evaluate the model using the `X_test` and `y_test` data.\n",
    "2. Use the X_test data to make predictions\n",
    "3. Create a DataFrame of Real (y_test) vs predicted values. \n",
    "4. Plot the Real vs predicted values as a line chart\n",
    "\n",
    "### Hints\n",
    "Remember to apply the `inverse_transform` function to the predicted and y_test values to recover the actual closing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_prices = y_test_scaler.inverse_transform(predicted.reshape(-1, 1))\n",
    "real_prices = y_test_scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "stocks = pd.DataFrame({\n",
    "    \"Real\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "}, index = df.index[-len(real_prices): ]) \n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the real vs predicted values as a line chart\n",
    "stocks.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyvizenv] *",
   "language": "python",
   "name": "conda-env-pyvizenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
